[cloudera@quickstart ~]$ bash /home/cloudera/Desktop/exo51/exo51.sh
Running exo 5_1
Downloading files... 
mkdir: `input51': File exists
--2018-03-14 18:02:40--  http://www.textfiles.com/etext/FICTION/defoe-robinson-103.txt
Resolving www.textfiles.com... 208.86.224.90
Connecting to www.textfiles.com|208.86.224.90|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 624405 (610K) [text/plain]
Saving to: “defoe-robinson-103.txt”

100%[======================================>] 624,405      607K/s   in 1.0s    

2018-03-14 18:02:41 (607 KB/s) - “defoe-robinson-103.txt” saved [624405/624405]

--2018-03-14 18:02:45--  http://www.textfiles.com/etext/FICTION/callwild
Resolving www.textfiles.com... 208.86.224.90
Connecting to www.textfiles.com|208.86.224.90|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 175998 (172K)
Saving to: “callwild”

100%[======================================>] 175,998     --.-K/s   in 0.1s    

2018-03-14 18:02:46 (1.28 MB/s) - “callwild” saved [175998/175998]

Round 1 : word count ...
18/03/14 18:02:50 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/cloudera/Desktop/exo51/mapper51_1.py, /home/cloudera/Desktop/exo51/reducer51_1.py] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.12.0.jar] /tmp/streamjob6646191892157400044.jar tmpDir=null
18/03/14 18:02:52 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
18/03/14 18:02:52 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
18/03/14 18:02:53 INFO mapred.FileInputFormat: Total input paths to process : 2
18/03/14 18:02:53 INFO mapreduce.JobSubmitter: number of splits:3
18/03/14 18:02:54 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1515684464387_0142
18/03/14 18:02:54 INFO impl.YarnClientImpl: Submitted application application_1515684464387_0142
18/03/14 18:02:54 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1515684464387_0142/
18/03/14 18:02:54 INFO mapreduce.Job: Running job: job_1515684464387_0142
18/03/14 18:03:06 INFO mapreduce.Job: Job job_1515684464387_0142 running in uber mode : false
18/03/14 18:03:06 INFO mapreduce.Job:  map 0% reduce 0%
18/03/14 18:03:34 INFO mapreduce.Job:  map 67% reduce 0%
18/03/14 18:03:35 INFO mapreduce.Job:  map 100% reduce 0%
18/03/14 18:03:52 INFO mapreduce.Job:  map 100% reduce 100%
18/03/14 18:03:52 INFO mapreduce.Job: Job job_1515684464387_0142 completed successfully
18/03/14 18:03:52 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=3978423
		FILE: Number of bytes written=8470999
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=804869
		HDFS: Number of bytes written=285271
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=3
		Launched reduce tasks=1
		Data-local map tasks=3
		Total time spent by all maps in occupied slots (ms)=79237
		Total time spent by all reduces in occupied slots (ms)=13753
		Total time spent by all map tasks (ms)=79237
		Total time spent by all reduce tasks (ms)=13753
		Total vcore-milliseconds taken by all map tasks=79237
		Total vcore-milliseconds taken by all reduce tasks=13753
		Total megabyte-milliseconds taken by all map tasks=81138688
		Total megabyte-milliseconds taken by all reduce tasks=14083072
	Map-Reduce Framework
		Map input records=13490
		Map output records=153227
		Map output bytes=3671963
		Map output materialized bytes=3978435
		Input split bytes=370
		Combine input records=0
		Combine output records=0
		Reduce input groups=11634
		Reduce shuffle bytes=3978435
		Reduce input records=153227
		Reduce output records=11634
		Spilled Records=306454
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=1426
		CPU time spent (ms)=7710
		Physical memory (bytes) snapshot=766877696
		Virtual memory (bytes) snapshot=6028566528
		Total committed heap usage (bytes)=557592576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=804499
	File Output Format Counters 
		Bytes Written=285271
18/03/14 18:03:52 INFO streaming.StreamJob: Output directory: output51_1
Round 2 : word count per doc...
18/03/14 18:03:57 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/cloudera/Desktop/exo51/mapper51_2.py, /home/cloudera/Desktop/exo51/reducer51_2.py] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.12.0.jar] /tmp/streamjob5899226450165879044.jar tmpDir=null
18/03/14 18:03:59 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
18/03/14 18:04:00 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
18/03/14 18:04:01 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1281)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:952)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:690)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:879)
18/03/14 18:04:01 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1281)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:952)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:690)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:879)
18/03/14 18:04:01 INFO mapred.FileInputFormat: Total input paths to process : 1
18/03/14 18:04:01 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1281)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:952)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:690)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:879)
18/03/14 18:04:01 WARN hdfs.DFSClient: Caught exception 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1281)
	at java.lang.Thread.join(Thread.java:1355)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.closeResponder(DFSOutputStream.java:952)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.endBlock(DFSOutputStream.java:690)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:879)
18/03/14 18:04:01 INFO mapreduce.JobSubmitter: number of splits:2
18/03/14 18:04:02 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1515684464387_0143
18/03/14 18:04:02 INFO impl.YarnClientImpl: Submitted application application_1515684464387_0143
18/03/14 18:04:02 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1515684464387_0143/
18/03/14 18:04:02 INFO mapreduce.Job: Running job: job_1515684464387_0143
18/03/14 18:04:12 INFO mapreduce.Job: Job job_1515684464387_0143 running in uber mode : false
18/03/14 18:04:12 INFO mapreduce.Job:  map 0% reduce 0%
18/03/14 18:04:23 INFO mapreduce.Job:  map 50% reduce 0%
18/03/14 18:04:24 INFO mapreduce.Job:  map 100% reduce 0%
18/03/14 18:04:31 INFO mapreduce.Job:  map 100% reduce 100%
18/03/14 18:04:32 INFO mapreduce.Job: Job job_1515684464387_0143 completed successfully
18/03/14 18:04:32 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=308545
		FILE: Number of bytes written=1002733
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=289605
		HDFS: Number of bytes written=343441
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Killed map tasks=1
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=19363
		Total time spent by all reduces in occupied slots (ms)=5802
		Total time spent by all map tasks (ms)=19363
		Total time spent by all reduce tasks (ms)=5802
		Total vcore-milliseconds taken by all map tasks=19363
		Total vcore-milliseconds taken by all reduce tasks=5802
		Total megabyte-milliseconds taken by all map tasks=19827712
		Total megabyte-milliseconds taken by all reduce tasks=5941248
	Map-Reduce Framework
		Map input records=11634
		Map output records=11634
		Map output bytes=285271
		Map output materialized bytes=308551
		Input split bytes=238
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=308551
		Reduce input records=11634
		Reduce output records=11634
		Spilled Records=23268
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=289
		CPU time spent (ms)=3190
		Physical memory (bytes) snapshot=600698880
		Virtual memory (bytes) snapshot=4524470272
		Total committed heap usage (bytes)=391979008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=289367
	File Output Format Counters 
		Bytes Written=343441
18/03/14 18:04:32 INFO streaming.StreamJob: Output directory: output51_2
Round 3 :doc word per count and tf-idf calcultion ... 
18/03/14 18:04:37 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
packageJobJar: [/home/cloudera/Desktop/exo51/mapper51_3.py, /home/cloudera/Desktop/exo51/reducer51_3.py] [/usr/lib/hadoop-mapreduce/hadoop-streaming-2.6.0-cdh5.12.0.jar] /tmp/streamjob4930558015591299912.jar tmpDir=null
18/03/14 18:04:39 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
18/03/14 18:04:39 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
18/03/14 18:04:40 INFO mapred.FileInputFormat: Total input paths to process : 1
18/03/14 18:04:40 INFO mapreduce.JobSubmitter: number of splits:2
18/03/14 18:04:40 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1515684464387_0144
18/03/14 18:04:41 INFO impl.YarnClientImpl: Submitted application application_1515684464387_0144
18/03/14 18:04:41 INFO mapreduce.Job: The url to track the job: http://quickstart.cloudera:8088/proxy/application_1515684464387_0144/
18/03/14 18:04:41 INFO mapreduce.Job: Running job: job_1515684464387_0144
18/03/14 18:04:49 INFO mapreduce.Job: Job job_1515684464387_0144 running in uber mode : false
18/03/14 18:04:49 INFO mapreduce.Job:  map 0% reduce 0%
18/03/14 18:05:01 INFO mapreduce.Job:  map 50% reduce 0%
18/03/14 18:05:02 INFO mapreduce.Job:  map 100% reduce 0%
18/03/14 18:05:09 INFO mapreduce.Job:  map 100% reduce 100%
18/03/14 18:05:10 INFO mapreduce.Job: Job job_1515684464387_0144 completed successfully
18/03/14 18:05:10 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=366715
		FILE: Number of bytes written=1119076
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=347775
		HDFS: Number of bytes written=783
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=18478
		Total time spent by all reduces in occupied slots (ms)=5663
		Total time spent by all map tasks (ms)=18478
		Total time spent by all reduce tasks (ms)=5663
		Total vcore-milliseconds taken by all map tasks=18478
		Total vcore-milliseconds taken by all reduce tasks=5663
		Total megabyte-milliseconds taken by all map tasks=18921472
		Total megabyte-milliseconds taken by all reduce tasks=5798912
	Map-Reduce Framework
		Map input records=11634
		Map output records=11634
		Map output bytes=343441
		Map output materialized bytes=366721
		Input split bytes=238
		Combine input records=0
		Combine output records=0
		Reduce input groups=9376
		Reduce shuffle bytes=366721
		Reduce input records=11634
		Reduce output records=20
		Spilled Records=23268
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=287
		CPU time spent (ms)=3210
		Physical memory (bytes) snapshot=600563712
		Virtual memory (bytes) snapshot=4524154880
		Total committed heap usage (bytes)=391979008
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=347537
	File Output Format Counters 
		Bytes Written=783
18/03/14 18:05:10 INFO streaming.StreamJob: Output directory: output51_3
The program run during 265 sec.
[cloudera@quickstart ~]$ 
